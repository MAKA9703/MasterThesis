{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade transformers==2.9.0"
      ],
      "metadata": {
        "id": "aYUERMWBQ1tj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade pytorch_lightning==0.7.5"
      ],
      "metadata": {
        "id": "rUE302IfQ8j2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install sentencepiece"
      ],
      "metadata": {
        "id": "LnSQZq8dRaiZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install t5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmdJuCvGTQBu",
        "outputId": "86db5a09-9a80-42aa-b683-2202f8e95a4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ml-dtypes>=0.2.0 (from jax->seqio-nightly->t5)\n",
            "  Downloading ml_dtypes-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.7/206.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading ml_dtypes-0.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.6/206.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow-text (from seqio-nightly->t5)\n",
            "  Downloading tensorflow_text-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow<2.15,>=2.14.0 (from tensorflow-text->seqio-nightly->t5)\n",
            "  Downloading tensorflow-2.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.9 MB)\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m489.9/489.9 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install pyterrier"
      ],
      "metadata": {
        "id": "gGdO3g4ETLZj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install python-terrier"
      ],
      "metadata": {
        "id": "whHAhzu2TLdP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "DG08vKGRTcv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pyterrier as pt\n",
        "if not pt.started():\n",
        "  pt.init(boot_packages=[\"com.github.terrierteam:terrier-prf:-SNAPSHOT\"])\n",
        "\n",
        "import torch\n",
        "from transformers import T5ForConditionalGeneration,T5Tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "dTLjWyakTdF3",
        "outputId": "c9c256ab-5ad4-46e9-ab3f-a7be8b67c02a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-260b078589f5>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyterrier\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboot_packages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"com.github.terrierteam:terrier-prf:-SNAPSHOT\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyterrier'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect To Google Drive And Load Data"
      ],
      "metadata": {
        "id": "8JDP2xekTVLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "amBysLHVTWcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/MyDrive/project_data'"
      ],
      "metadata": {
        "id": "5UBelaPkTbNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/MyDrive/project_data/scifact'"
      ],
      "metadata": {
        "id": "--oqOUbGTbP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_directory = '/content/drive/MyDrive/project_data'"
      ],
      "metadata": {
        "id": "4oPMsEsvTbSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Meta-Data"
      ],
      "metadata": {
        "id": "de_6wO44TFY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = pd.read_json(data_directory + '/scifact/corpus.jsonl', lines=True, dtype=str)\n",
        "\n",
        "corpus"
      ],
      "metadata": {
        "id": "bOZr2CCqTIDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Test data and qrels from .csv files"
      ],
      "metadata": {
        "id": "lYjk0lyGTslr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test data\n",
        "df_test = pd.read_csv(data_directory + '/scifact/test.csv', sep='\\t', dtype=str)\n",
        "print(df_test.shape)\n",
        "print(df_test['query'].apply(len).mean())\n",
        "print(df_test['text'].apply(len).mean())\n",
        "df_test"
      ],
      "metadata": {
        "id": "O5jIdED9Tr1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test_data\n",
        "df_test = pd.read_csv(data_directory + '/scifact/test.csv', sep='\\t', dtype=str)\n",
        "df_test2 = df_test[['qid', 'query']]\n",
        "df_test2.to_csv('my_test_queries.csv', sep = '\\t', index=False, header=False)\n",
        "test_query = pt.io.read_topics('my_test_queries.csv', format='singleline')\n",
        "test_query"
      ],
      "metadata": {
        "id": "q9c0UNYATr4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test qrels\n",
        "df_test_qrels = pd.read_csv(data_directory + '/scifact/qrels/test.tsv', sep='\\t', dtype=str)\n",
        "\n",
        "df_test_qrels"
      ],
      "metadata": {
        "id": "dr6zCF4qUEmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#source data\n",
        "test_source = test_query['query']\n",
        "test_source\n",
        "\n",
        "#target data\n",
        "test_target = df_test['text']\n",
        "\n",
        "test_target"
      ],
      "metadata": {
        "id": "9h70GFztUFSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# T5 - Query Rephrasing"
      ],
      "metadata": {
        "id": "DQ6yTGr6UPmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#INSPIRED BY!\n",
        "#https://github.com/ramsrigouthamg/Paraphrase-any-question-with-T5-Text-To-Text-Transfer-Transformer-\n",
        "def set_seed(seed):\n",
        "  torch.manual_seed(seed)\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(15)\n"
      ],
      "metadata": {
        "id": "jKDZtZW3VukF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = T5ForConditionalGeneration.from_pretrained('ramsrigouthamg/t5_paraphraser')\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print (\"device \",device)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "Lg7UpiGtQbVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_outputs = []\n",
        "for i in range(len(test_source)):\n",
        "  text =  \"paraphrase: \" + test_source.iloc[i] + \" </s>\"\n",
        "\n",
        "\n",
        "  max_len = 256\n",
        "\n",
        "  encoding = tokenizer.encode_plus(text,pad_to_max_length=True, return_tensors=\"pt\")\n",
        "  input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
        "\n",
        "\n",
        "  # set top_k = 50 and set top_p = 0.95 and num_return_sequences = 3\n",
        "  beam_outputs = model.generate(\n",
        "      input_ids=input_ids, attention_mask=attention_masks,\n",
        "      do_sample=True,\n",
        "      max_length=256,\n",
        "      top_k=120,\n",
        "      top_p=0.98,\n",
        "      early_stopping=True,\n",
        "      num_return_sequences=5\n",
        "  )\n",
        "\n",
        "  final_outputs =[]\n",
        "  for beam_output in beam_outputs:\n",
        "      sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
        "      if sent.lower() != test_source.iloc[i].lower() and sent not in final_outputs:\n",
        "          final_outputs.append(sent)\n",
        "  all_outputs.append(final_outputs)\n",
        "\n",
        "  if i == 0:\n",
        "    print (\"\\nOriginal Question ::\")\n",
        "    print (test_source.iloc[i])\n",
        "    print (\"\\n\")\n",
        "    print (\"Paraphrased Questions :: \")\n",
        "    for i, final_output in enumerate(final_outputs):\n",
        "        print(\"{}: {}\".format(i, final_output))\n",
        "\n",
        "  if i % 10 == 0:\n",
        "    print(i,  \" out of \", len(test_source))"
      ],
      "metadata": {
        "id": "g7vgtNqKQalz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rewritten_text1 = []\n",
        "rewritten_text2 = []\n",
        "rewritten_text3 = []\n",
        "rewritten_text4 = []\n",
        "rewritten_text5 = []\n",
        "\n",
        "counter = 0\n",
        "\n",
        "for i in range(len(all_outputs)):\n",
        "  rewritten_text1.append(all_outputs[i][0])\n",
        "\n",
        "for i in range(len(all_outputs)):\n",
        "  if len(all_outputs[i]) < 2:\n",
        "    counter += 1\n",
        "    rewritten_text2.append(all_outputs[i][0])\n",
        "  else:\n",
        "    rewritten_text2.append(all_outputs[i][1])\n",
        "\n",
        "for i in range(len(all_outputs)):\n",
        "  if len(all_outputs[i]) < 3:\n",
        "    rewritten_text3.append(all_outputs[i][0])\n",
        "  else:\n",
        "    rewritten_text3.append(all_outputs[i][2])\n",
        "\n",
        "for i in range(len(all_outputs)):\n",
        "  if len(all_outputs[i]) < 4:\n",
        "    rewritten_text4.append(all_outputs[i][0])\n",
        "  else:\n",
        "    rewritten_text4.append(all_outputs[i][3])\n",
        "\n",
        "for i in range(len(all_outputs)):\n",
        "  if len(all_outputs[i]) < 5:\n",
        "    rewritten_text5.append(all_outputs[i][0])\n",
        "  else:\n",
        "    rewritten_text5.append(all_outputs[i][4])\n",
        "\n",
        "print(counter)"
      ],
      "metadata": {
        "id": "RmzXfhWkWsrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation using BM25"
      ],
      "metadata": {
        "id": "z1IATGFgaz3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = corpus.rename(columns={'_id': 'docno'})\n",
        "corpus"
      ],
      "metadata": {
        "id": "RXSjKDIFa1kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexer = pt.DFIndexer(\"./indexes_scifact/both\", overwrite=True, blocks=True,verbose=True, stemmer='porter', stopwords='terrier', tokenizer = 'english')\n",
        "index_ref = indexer.index(corpus[\"text\"], corpus[\"docno\"])\n",
        "index = pt.IndexFactory.of(index_ref)"
      ],
      "metadata": {
        "id": "aiPbpPDba60c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")"
      ],
      "metadata": {
        "id": "TcDpWt6ta9lx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_queries1 = pd.DataFrame()\n",
        "new_queries1['qid'] = test_query['qid']\n",
        "new_queries1['query'] = test_source\n",
        "\n",
        "new_queries1 = pd.DataFrame()\n",
        "new_queries1['qid'] = test_query['qid']\n",
        "new_queries1['query'] = rewritten_text1\n",
        "\n",
        "new_queries2 = pd.DataFrame()\n",
        "new_queries2['qid'] = test_query['qid']\n",
        "new_queries2['query'] = rewritten_text2\n",
        "\n",
        "new_queries3 = pd.DataFrame()\n",
        "new_queries3['qid'] = test_query['qid']\n",
        "new_queries3['query'] = rewritten_text3\n",
        "\n",
        "new_queries4 = pd.DataFrame()\n",
        "new_queries4['qid'] = test_query['qid']\n",
        "new_queries4['query'] = rewritten_text4\n",
        "\n",
        "new_queries5 = pd.DataFrame()\n",
        "new_queries5['qid'] = test_query['qid']\n",
        "new_queries5['query'] = rewritten_text5"
      ],
      "metadata": {
        "id": "OW1j8y87bA_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_queries1['query'] = new_queries1['query'].str.replace('%','')\n",
        "new_queries1['query'] = new_queries1['query'].str.replace('?','')\n",
        "new_queries1['query'] = new_queries1['query'].str.replace('\\'','')\n",
        "new_queries1['query'] = new_queries1['query'].str.replace('(','')\n",
        "new_queries1['query'] = new_queries1['query'].str.replace(')','')\n",
        "new_queries1['query'] = new_queries1['query'].str.replace(':','')\n",
        "new_queries1['query'] = new_queries1['query'].str.replace('/','')\n",
        "\n",
        "new_queries2['query'] = new_queries2['query'].str.replace('%','')\n",
        "new_queries2['query'] = new_queries2['query'].str.replace('?','')\n",
        "new_queries2['query'] = new_queries2['query'].str.replace('\\'','')\n",
        "new_queries2['query'] = new_queries2['query'].str.replace('(','')\n",
        "new_queries2['query'] = new_queries2['query'].str.replace(')','')\n",
        "new_queries2['query'] = new_queries2['query'].str.replace(':','')\n",
        "new_queries2['query'] = new_queries2['query'].str.replace('/','')\n",
        "\n",
        "new_queries3['query'] = new_queries3['query'].str.replace('%','')\n",
        "new_queries3['query'] = new_queries3['query'].str.replace('?','')\n",
        "new_queries3['query'] = new_queries3['query'].str.replace('\\'','')\n",
        "new_queries3['query'] = new_queries3['query'].str.replace('(','')\n",
        "new_queries3['query'] = new_queries3['query'].str.replace(')','')\n",
        "new_queries3['query'] = new_queries3['query'].str.replace(':','')\n",
        "new_queries3['query'] = new_queries3['query'].str.replace('/','')\n",
        "\n",
        "new_queries4['query'] = new_queries4['query'].str.replace('%','')\n",
        "new_queries4['query'] = new_queries4['query'].str.replace('?','')\n",
        "new_queries4['query'] = new_queries4['query'].str.replace('\\'','')\n",
        "new_queries4['query'] = new_queries4['query'].str.replace('(','')\n",
        "new_queries4['query'] = new_queries4['query'].str.replace(')','')\n",
        "new_queries4['query'] = new_queries4['query'].str.replace(':','')\n",
        "new_queries4['query'] = new_queries4['query'].str.replace('/','')\n",
        "\n",
        "new_queries5['query'] = new_queries5['query'].str.replace('%','')\n",
        "new_queries5['query'] = new_queries5['query'].str.replace('?','')\n",
        "new_queries5['query'] = new_queries5['query'].str.replace('\\'','')\n",
        "new_queries5['query'] = new_queries5['query'].str.replace('(','')\n",
        "new_queries5['query'] = new_queries5['query'].str.replace(')','')\n",
        "new_queries5['query'] = new_queries5['query'].str.replace(':','')\n",
        "new_queries5['query'] = new_queries5['query'].str.replace('/','')"
      ],
      "metadata": {
        "id": "YGYjXJeklJ1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comb_rewritten_texts = []\n",
        "for i in range(len(rewritten_text1)):\n",
        "  res = test_source + \" \" + rewritten_text1[i] + \" \" + rewritten_text2[i] + \" \" + rewritten_text3[i] + \" \" + rewritten_text4[i] + \" \" + rewritten_text5[i]\n",
        "  comb_rewritten_texts.append(res)\n",
        "\n",
        "new_queries6 = pd.DataFrame()\n",
        "new_queries6['qid'] = test_query['qid']\n",
        "new_queries6['query'] = comb_rewritten_texts"
      ],
      "metadata": {
        "id": "gxCl7YEBdvRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_qrels = df_test_qrels.rename(columns={\"query-id\": \"qid\", \"corpus-id\" : \"docno\", \"score\": \"label\"})\n",
        "test_qrels['iteration'] = 0\n",
        "qrels = test_qrels.astype({'label': 'int32'})\n",
        "qrels"
      ],
      "metadata": {
        "id": "zjbDY26ibGYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_res_ndcg = pt.Experiment(\n",
        "                        retr_systems = [bm25],\n",
        "                        names =  [\"BM25\"],\n",
        "                        topics = new_queries1,\n",
        "                        qrels = qrels,\n",
        "                        eval_metrics = [\"ndcg_cut_10\", \"ndcg_cut_100\", \"ndcg_cut_1000\"])\n",
        "\n",
        "final_res_map = pt.Experiment(\n",
        "                        retr_systems = [bm25],\n",
        "                        names =  [\"BM25\"],\n",
        "                        topics = new_queries1,\n",
        "                        qrels = qrels,\n",
        "                        eval_metrics = [\"map_cut_10\", \"map_cut_100\", \"map_cut_1000\"])\n",
        "\n",
        "final_res_precision = pt.Experiment(\n",
        "                        retr_systems = [bm25],\n",
        "                        names =  [\"BM25\"],\n",
        "                        topics = new_queries1,\n",
        "                        qrels = qrels,\n",
        "                        eval_metrics = [\"P_10\", \"P_100\", \"P_1000\"])\n",
        "\n",
        "final_res_recall = pt.Experiment(\n",
        "                        retr_systems = [bm25],\n",
        "                        names =  [\"BM25\"],\n",
        "                        topics = new_queries1,\n",
        "                        qrels = qrels,\n",
        "                        eval_metrics = [\"recall_10\", \"recall_100\", \"recall_1000\"])\n",
        "\n",
        "print(final_res_ndcg)\n",
        "print(final_res_map)\n",
        "print(final_res_precision)\n",
        "print(final_res_recall)"
      ],
      "metadata": {
        "id": "x23xMUVhbKyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_res_ndcg2 = pt.Experiment(\n",
        "                        retr_systems = [bm25],\n",
        "                        names =  [\"BM25\"],\n",
        "                        topics = new_queries2,\n",
        "                        qrels = qrels,\n",
        "                        eval_metrics = [\"ndcg_cut_10\", \"ndcg_cut_100\", \"ndcg_cut_1000\"])\n",
        "\n",
        "final_res_map2 = pt.Experiment(\n",
        "                        retr_systems = [bm25],\n",
        "                        names =  [\"BM25\"],\n",
        "                        topics = new_queries2,\n",
        "                        qrels = qrels,\n",
        "                        eval_metrics = [\"map_cut_10\", \"map_cut_100\", \"map_cut_1000\"])\n",
        "\n",
        "final_res_precision2 = pt.Experiment(\n",
        "                        retr_systems = [bm25],\n",
        "                        names =  [\"BM25\"],\n",
        "                        topics = new_queries2,\n",
        "                        qrels = qrels,\n",
        "                        eval_metrics = [\"P_10\", \"P_100\", \"P_1000\"])\n",
        "\n",
        "final_res_recall2 = pt.Experiment(\n",
        "                        retr_systems = [bm25],\n",
        "                        names =  [\"BM25\"],\n",
        "                        topics = new_queries2,\n",
        "                        qrels = qrels,\n",
        "                        eval_metrics = [\"recall_10\", \"recall_100\", \"recall_1000\"])\n",
        "\n",
        "print(final_res_ndcg2)\n",
        "print(final_res_map2)\n",
        "print(final_res_precision2)\n",
        "print(final_res_recall2)"
      ],
      "metadata": {
        "id": "fEJhhGn_p2rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_res_ndcg3 = pt.Experiment(\n",
        "                        retr_systems = [bm25],\n",
        "                        names =  [\"BM25\"],\n",
        "                        topics = new_queries3,\n",
        "                        qrels = qrels,\n",
        "                        eval_metrics = [\"ndcg_cut_10\", \"ndcg_cut_100\", \"ndcg_cut_1000\"])\n",
        "\n",
        "final_res_map3 = pt.Experiment(\n",
        "                        retr_systems = [bm25],\n",
        "                        names =  [\"BM25\"],\n",
        "                        topics = new_queries3,\n",
        "                        qrels = qrels,\n",
        "                        eval_metrics = [\"map_cut_10\", \"map_cut_100\", \"map_cut_1000\"])\n",
        "\n",
        "final_res_precision3 = pt.Experiment(\n",
        "                        retr_systems = [bm25],\n",
        "                        names =  [\"BM25\"],\n",
        "                        topics = new_queries3,\n",
        "                        qrels = qrels,\n",
        "                        eval_metrics = [\"P_10\", \"P_100\", \"P_1000\"])\n",
        "\n",
        "final_res_recall3 = pt.Experiment(\n",
        "                        retr_systems = [bm25],\n",
        "                        names =  [\"BM25\"],\n",
        "                        topics = new_queries3,\n",
        "                        qrels = qrels,\n",
        "                        eval_metrics = [\"recall_10\", \"recall_100\", \"recall_1000\"])\n",
        "\n",
        "print(final_res_ndcg3)\n",
        "print(final_res_map3)\n",
        "print(final_res_precision3)\n",
        "print(final_res_recall3)"
      ],
      "metadata": {
        "id": "ydIPMECkp20R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_res_ndcg4 = pt.Experiment(\n",
        "                        retr_systems = [bm25],\n",
        "                        names =  [\"BM25\"],\n",
        "                        topics = new_queries4,\n",
        "                        qrels = qrels,\n",
        "                        eval_metrics = [\"ndcg_cut_10\", \"ndcg_cut_100\", \"ndcg_cut_1000\"])\n",
        "\n",
        "final_res_map4 = pt.Experiment(\n",
        "                        retr_systems = [bm25],\n",
        "                        names =  [\"BM25\"],\n",
        "                        topics = new_queries4,\n",
        "                        qrels = qrels,\n",
        "                        eval_metrics = [\"map_cut_10\", \"map_cut_100\", \"map_cut_1000\"])\n",
        "\n",
        "final_res_precision4 = pt.Experiment(\n",
        "                        retr_systems = [bm25],\n",
        "                        names =  [\"BM25\"],\n",
        "                        topics = new_queries4,\n",
        "                        qrels = qrels,\n",
        "                        eval_metrics = [\"P_10\", \"P_100\", \"P_1000\"])\n",
        "\n",
        "final_res_recall4 = pt.Experiment(\n",
        "                        retr_systems = [bm25],\n",
        "                        names =  [\"BM25\"],\n",
        "                        topics = new_queries4,\n",
        "                        qrels = qrels,\n",
        "                        eval_metrics = [\"recall_10\", \"recall_100\", \"recall_1000\"])\n",
        "\n",
        "print(final_res_ndcg4)\n",
        "print(final_res_map4)\n",
        "print(final_res_precision4)\n",
        "print(final_res_recall4)"
      ],
      "metadata": {
        "id": "1nvRSWa9p29z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_res_ndcg5 = pt.Experiment(\n",
        "                        retr_systems = [bm25],\n",
        "                        names =  [\"BM25\"],\n",
        "                        topics = new_queries5,\n",
        "                        qrels = qrels,\n",
        "                        eval_metrics = [\"ndcg_cut_10\", \"ndcg_cut_100\", \"ndcg_cut_1000\"])\n",
        "\n",
        "final_res_map5 = pt.Experiment(\n",
        "                        retr_systems = [bm25],\n",
        "                        names =  [\"BM25\"],\n",
        "                        topics = new_queries5,\n",
        "                        qrels = qrels,\n",
        "                        eval_metrics = [\"map_cut_10\", \"map_cut_100\", \"map_cut_1000\"])\n",
        "\n",
        "final_res_precision5 = pt.Experiment(\n",
        "                        retr_systems = [bm25],\n",
        "                        names =  [\"BM25\"],\n",
        "                        topics = new_queries5,\n",
        "                        qrels = qrels,\n",
        "                        eval_metrics = [\"P_10\", \"P_100\", \"P_1000\"])\n",
        "\n",
        "final_res_recall5 = pt.Experiment(\n",
        "                        retr_systems = [bm25],\n",
        "                        names =  [\"BM25\"],\n",
        "                        topics = new_queries5,\n",
        "                        qrels = qrels,\n",
        "                        eval_metrics = [\"recall_10\", \"recall_100\", \"recall_1000\"])\n",
        "\n",
        "print(final_res_ndcg5)\n",
        "print(final_res_map5)\n",
        "print(final_res_precision5)\n",
        "print(final_res_recall5)"
      ],
      "metadata": {
        "id": "hFbM0FUxp3GN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_res_ndcg6 = pt.Experiment(\n",
        "                        retr_systems = [bm25],\n",
        "                        names =  [\"BM25\"],\n",
        "                        topics = new_queries6,\n",
        "                        qrels = qrels,\n",
        "                        eval_metrics = [\"ndcg_cut_10\", \"ndcg_cut_100\", \"ndcg_cut_1000\"])\n",
        "\n",
        "final_res_map6 = pt.Experiment(\n",
        "                        retr_systems = [bm25],\n",
        "                        names =  [\"BM25\"],\n",
        "                        topics = new_queries6,\n",
        "                        qrels = qrels,\n",
        "                        eval_metrics = [\"map_cut_10\", \"map_cut_100\", \"map_cut_1000\"])\n",
        "\n",
        "final_res_precision6 = pt.Experiment(\n",
        "                        retr_systems = [bm25],\n",
        "                        names =  [\"BM25\"],\n",
        "                        topics = new_queries6,\n",
        "                        qrels = qrels,\n",
        "                        eval_metrics = [\"P_10\", \"P_100\", \"P_1000\"])\n",
        "\n",
        "final_res_recall6 = pt.Experiment(\n",
        "                        retr_systems = [bm25],\n",
        "                        names =  [\"BM25\"],\n",
        "                        topics = new_queries6,\n",
        "                        qrels = qrels,\n",
        "                        eval_metrics = [\"recall_10\", \"recall_100\", \"recall_1000\"])\n",
        "\n",
        "print(final_res_ndcg6)\n",
        "print(final_res_map6)\n",
        "print(final_res_precision6)\n",
        "print(final_res_recall6)"
      ],
      "metadata": {
        "id": "tXmq7emuhW61"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}