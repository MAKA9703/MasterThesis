{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "edbbc9a0",
      "metadata": {
        "id": "edbbc9a0"
      },
      "source": [
        "# Toy Examples DPR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc3f2125",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc3f2125",
        "outputId": "69bb8c0b-fc13-48dc-a449-710dea270fe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beir in /usr/local/lib/python3.10/dist-packages (2.0.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (from beir) (2.2.2)\n",
            "Requirement already satisfied: pytrec-eval in /usr/local/lib/python3.10/dist-packages (from beir) (0.5)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (from beir) (1.7.4)\n",
            "Requirement already satisfied: elasticsearch==7.9.1 in /usr/local/lib/python3.10/dist-packages (from beir) (7.9.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from beir) (2.15.0)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from elasticsearch==7.9.1->beir) (2.0.7)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from elasticsearch==7.9.1->beir) (2023.11.17)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (6.0.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (4.35.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (0.16.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (0.1.99)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (4.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets->beir) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets->beir) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->beir) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->beir) (3.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers->beir) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers->beir) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers->beir) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers->beir) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers->beir) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers->beir) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers->beir) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers->beir) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers->beir) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->beir) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->beir) (2023.3.post1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers->beir) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers->beir) (9.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->beir) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers->beir) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers->beir) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "#https://github.com/beir-cellar/beir/blob/main/examples/retrieval/evaluation/dense/evaluate_dpr.py\n",
        "!pip install beir"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c6d64f8",
      "metadata": {
        "id": "3c6d64f8"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c383100",
      "metadata": {
        "id": "7c383100"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5901d944",
      "metadata": {
        "id": "5901d944"
      },
      "source": [
        "# Load Toy Data-Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "680f5992",
      "metadata": {
        "id": "680f5992"
      },
      "outputs": [],
      "source": [
        "#documents\n",
        "docs = pd.read_csv('./toy_data/docs.csv', dtype=str)\n",
        "\n",
        "#queries\n",
        "queries = pd.read_csv('./toy_data/queries.csv', dtype=str)\n",
        "\n",
        "#qrels\n",
        "qrels = pd.read_csv('./toy_data/qrels.csv', dtype=str)\n",
        "qrels = qrels.astype({'label': 'int32'})\n",
        "\n",
        "\n",
        "#prints\n",
        "print(docs.shape)\n",
        "print(docs.head())\n",
        "\n",
        "print(queries.shape)\n",
        "print(queries.head())\n",
        "\n",
        "print(qrels.shape)\n",
        "print(qrels.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1642f52",
      "metadata": {
        "id": "e1642f52"
      },
      "source": [
        "# Dense IR - Using Dense Passage Retrieval (DPR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d39c0e6",
      "metadata": {
        "id": "9d39c0e6"
      },
      "outputs": [],
      "source": [
        "from beir import util, LoggingHandler\n",
        "from beir.retrieval import models\n",
        "from beir.datasets.data_loader import GenericDataLoader\n",
        "from beir.retrieval.evaluation import EvaluateRetrieval\n",
        "from beir.retrieval.search.dense import DenseRetrievalExactSearch as DRES\n",
        "\n",
        "import logging\n",
        "import pathlib, os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4208a6d9",
      "metadata": {
        "id": "4208a6d9"
      },
      "outputs": [],
      "source": [
        "#IMPLEMENTED MODEL FROM https://github.com/beir-cellar/beir\n",
        "#https://github.com/beir-cellar/beir/blob/main/beir/retrieval/models/dpr.py\n",
        "\n",
        "from transformers import DPRContextEncoder, DPRContextEncoderTokenizerFast\n",
        "from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizerFast\n",
        "from typing import Union, List, Dict, Tuple\n",
        "from tqdm.autonotebook import trange\n",
        "import torch\n",
        "\n",
        "class DPR:\n",
        "    def __init__(self, model_path: Union[str, Tuple] = None, **kwargs):\n",
        "        # Query tokenizer and model\n",
        "        self.q_tokenizer = DPRQuestionEncoderTokenizerFast.from_pretrained(model_path[0])\n",
        "        self.q_model = DPRQuestionEncoder.from_pretrained(model_path[0])\n",
        "        self.q_model.cuda()\n",
        "        self.q_model.eval()\n",
        "\n",
        "        # Context tokenizer and model\n",
        "        self.ctx_tokenizer = DPRContextEncoderTokenizerFast.from_pretrained(model_path[1])\n",
        "        self.ctx_model = DPRContextEncoder.from_pretrained(model_path[1])\n",
        "        self.ctx_model.cuda()\n",
        "        self.ctx_model.eval()\n",
        "\n",
        "    def encode_queries(self, queries: List[str], batch_size: int = 16, **kwargs) -> torch.Tensor:\n",
        "        query_embeddings = []\n",
        "        with torch.no_grad():\n",
        "            for start_idx in trange(0, len(queries), batch_size):\n",
        "                encoded = self.q_tokenizer(queries[start_idx:start_idx+batch_size], truncation=True, padding=True, return_tensors='pt')\n",
        "                model_out = self.q_model(encoded['input_ids'].cuda(), attention_mask=encoded['attention_mask'].cuda())\n",
        "                #model_out = self.q_model(encoded['input_ids'], attention_mask=encoded['attention_mask'])\n",
        "                query_embeddings += model_out.pooler_output\n",
        "\n",
        "        return torch.stack(query_embeddings)\n",
        "\n",
        "    def encode_corpus(self, corpus: List[Dict[str, str]], batch_size: int = 8, **kwargs) -> torch.Tensor:\n",
        "\n",
        "        corpus_embeddings = []\n",
        "        with torch.no_grad():\n",
        "            for start_idx in trange(0, len(corpus), batch_size):\n",
        "                #titles = [row['title'] for row in corpus[start_idx:start_idx+batch_size]]\n",
        "                texts = [row['text']  for row in corpus[start_idx:start_idx+batch_size]]\n",
        "                #encoded = self.ctx_tokenizer(titles, texts, truncation='longest_first', padding=True, return_tensors='pt')\n",
        "                encoded = self.ctx_tokenizer(texts, truncation='longest_first', padding=True, return_tensors='pt')\n",
        "                model_out = self.ctx_model(encoded['input_ids'].cuda(), attention_mask=encoded['attention_mask'].cuda())\n",
        "                #model_out = self.ctx_model(encoded['input_ids'], attention_mask=encoded['attention_mask'])\n",
        "                corpus_embeddings += model_out.pooler_output.detach()\n",
        "\n",
        "        return torch.stack(corpus_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86e09581",
      "metadata": {
        "id": "86e09581"
      },
      "outputs": [],
      "source": [
        "new_docs = {}\n",
        "for i in range(len(docs)):\n",
        "    new_docs[docs['docno'][i]] = {'text' : docs['text'][i]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06e16ddd",
      "metadata": {
        "id": "06e16ddd"
      },
      "outputs": [],
      "source": [
        "new_queries = {}\n",
        "for i in range(len(queries)):\n",
        "    new_queries[queries['qid'][i]] = queries['query'][i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e40cf64",
      "metadata": {
        "id": "0e40cf64"
      },
      "outputs": [],
      "source": [
        "new_qrels = {}\n",
        "for i in range(len(qrels)):\n",
        "    new_qrels[qrels['qid'][i]] = {qrels['docno'][i] : int(qrels['label'][i])}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17356778",
      "metadata": {
        "id": "17356778"
      },
      "outputs": [],
      "source": [
        "model_dpr = DRES(DPR((\n",
        "     \"facebook/dpr-question_encoder-multiset-base\",\n",
        "     \"facebook/dpr-ctx_encoder-multiset-base\"), batch_size=16))\n",
        "retriever_dpr = EvaluateRetrieval(model_dpr, score_function=\"dot\") # or \"dot\" for dot-product\n",
        "results_dpr = retriever_dpr.retrieve(new_docs, new_queries)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = DRES(models.SentenceBERT(\"msmarco-distilbert-base-tas-b\"), batch_size=16)\n",
        "retriever = EvaluateRetrieval(model, score_function=\"dot\") # or \"cos_sim\" for cosine similarity\n",
        "results = retriever.retrieve(new_docs, new_queries)"
      ],
      "metadata": {
        "id": "lOEnUeTx2ztE"
      },
      "id": "lOEnUeTx2ztE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://www.sbert.net/docs/pretrained-models/msmarco-v3.html\n",
        "#model_ance = DRES(models.SentenceBERT('msmarco-distilroberta-base-v3'))\n",
        "model_ance = DRES(models.SentenceBERT('msmarco-roberta-base-v3'))\n",
        "#model_ance = DRES(models.SentenceBERT('msmarco-distilbert-base-tas-b'))\n",
        "retriever_ance = EvaluateRetrieval(model_ance, score_function=\"cos_sim\")\n",
        "\n",
        "#### Retrieve dense results (format of results is identical to qrels)\n",
        "results_ance = retriever_ance.retrieve(new_docs, new_queries)"
      ],
      "metadata": {
        "id": "I_umnOqM5qWW"
      },
      "id": "I_umnOqM5qWW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dpr_alt = DRES(models.SentenceBERT((\n",
        "    \"facebook-dpr-question_encoder-multiset-base\",\n",
        "    \"facebook-dpr-ctx_encoder-multiset-base\",\n",
        "    \" [SEP] \"), batch_size=128))\n",
        "retriever_dpr_alt = EvaluateRetrieval(model_dpr_alt, score_function=\"dot\")\n",
        "results_dpr_alt = retriever_dpr_alt.retrieve(new_docs, new_queries)"
      ],
      "metadata": {
        "id": "d8Ule33z6tHS"
      },
      "id": "d8Ule33z6tHS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e3425f7",
      "metadata": {
        "id": "6e3425f7"
      },
      "outputs": [],
      "source": [
        "#### Evaluate your model with NDCG@k, MAP@K, Recall@K and Precision@K  where k = [1,3,5,10,100,1000] [10,100,100]\n",
        "ndcg, _map, recall, precision = retriever_dpr.evaluate(new_qrels, results_dpr, [10,100,1000]) #retriever_dpr.k_values)\n",
        "ndcg_alt, _map_alt, recall_alt, precision_alt = retriever.evaluate(new_qrels,results, [10,100,1000]) # retriever.k_values)\n",
        "ndcg_ance, _map_ance, recall_ance, precision_ance = retriever_ance.evaluate(new_qrels, results_ance, [10,100,1000]) #retriever_ance.k_values)\n",
        "ndcg_dpr_alt, _map_dpr_alt, recall_dpr_alt, precision_dpr_alt = retriever_dpr_alt.evaluate(new_qrels, results_dpr_alt, [10,100,1000]) #retriever_dpr_alt.k_values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15fabc98",
      "metadata": {
        "id": "15fabc98"
      },
      "outputs": [],
      "source": [
        "print(\"Original DPR:\", ndcg)\n",
        "print(\"Original Sentence BERT:\", ndcg_alt)\n",
        "print(\"Original ANCE:\", ndcg_ance)\n",
        "print(\"Alternative DPR\", ndcg_dpr_alt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87f7321f",
      "metadata": {
        "id": "87f7321f"
      },
      "outputs": [],
      "source": [
        "print(\"Original DPR:\", _map)\n",
        "print(\"Original Sentence BERT:\", _map_alt)\n",
        "print(\"Original ANCE:\", _map_ance)\n",
        "print(\"Alternative DPR\", _map_dpr_alt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac9b2e25",
      "metadata": {
        "id": "ac9b2e25"
      },
      "outputs": [],
      "source": [
        "print(\"Original DPR:\", recall)\n",
        "print(\"Original Sentence BERT:\", recall_alt)\n",
        "print(\"Original ANCE:\", recall_ance)\n",
        "print(\"Alternative DPR\", recall_dpr_alt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d9ea7b0",
      "metadata": {
        "id": "5d9ea7b0"
      },
      "outputs": [],
      "source": [
        "print(\"Original DPR:\", precision)\n",
        "print(\"Original Sentence BERT:\", precision_alt)\n",
        "print(\"Original ANCE:\", precision_ance)\n",
        "print(\"Alternative DPR\", precision_dpr_alt)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y_Vs_f7W4O4K"
      },
      "id": "y_Vs_f7W4O4K",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}