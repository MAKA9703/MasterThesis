{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edbbc9a0",
   "metadata": {},
   "source": [
    "# Toy Examples of Sparse and Dense IR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6d64f8",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c383100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5901d944",
   "metadata": {},
   "source": [
    "# Load Toy Data-Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "680f5992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2453, 2)\n",
      "     docno                                               text\n",
      "0   935016  he emigrated to france with his family in 1956...\n",
      "1  2360440  after being ambushed by the germans in novembe...\n",
      "2   347765  she was the second ship named for captain alex...\n",
      "3  1969335  world war ii was a global war that was under w...\n",
      "4  1576938  the ship was ordered on 2 april 1942 laid down...\n",
      "(9, 2)\n",
      "       qid                 query\n",
      "0  1015979    president of chile\n",
      "1     2674    computer animation\n",
      "2   340095  2020 summer olympics\n",
      "3  1502917         train station\n",
      "4     2574       chinese cuisine\n",
      "(2454, 4)\n",
      "       qid    docno label iteration\n",
      "0  1015979  1015979     2         0\n",
      "1  1015979  2226456     1         0\n",
      "2  1015979  1514612     1         0\n",
      "3  1015979  1119171     1         0\n",
      "4  1015979  1053174     1         0\n"
     ]
    }
   ],
   "source": [
    "#documents\n",
    "docs = pd.read_csv('./toy_data/docs.csv', dtype=str)\n",
    "\n",
    "#queries\n",
    "queries = pd.read_csv('./toy_data/queries.csv', dtype=str)\n",
    "\n",
    "#qrels\n",
    "qrels = pd.read_csv('./toy_data/qrels.csv', dtype=str)\n",
    "\n",
    "\n",
    "#prints\n",
    "print(docs.shape)\n",
    "print(docs.head())\n",
    "\n",
    "print(queries.shape)\n",
    "print(queries.head())\n",
    "\n",
    "print(qrels.shape)\n",
    "print(qrels.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69671b36",
   "metadata": {},
   "source": [
    "# Implement PyTerrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a6b509c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.9.2 has loaded Terrier 5.8 (built by craigm on 2023-11-01 18:05) and terrier-helper 0.0.8\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "if not pt.started():\n",
    "    pt.init(boot_packages=[\"com.github.terrierteam:terrier-prf:-SNAPSHOT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5dae786",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelayoub/opt/anaconda3/lib/python3.9/site-packages/pyterrier/index.py:628: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, value in meta_column[1].iteritems():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 2453\n",
      "Number of terms: 23693\n",
      "Number of postings: 208487\n",
      "Number of fields: 0\n",
      "Number of tokens: 273373\n",
      "Field names: []\n",
      "Positions:   true\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build DEFAULT index\n",
    "indexer = pt.DFIndexer(\"./indexes/default\", overwrite=True, blocks=True)\n",
    "index_ref = indexer.index(docs[\"text\"], docs[\"docno\"])\n",
    "index = pt.IndexFactory.of(index_ref)\n",
    "print(index.getCollectionStatistics().toString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "606cbc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 2453\n",
      "Number of terms: 23693\n",
      "Number of postings: 208487\n",
      "Number of fields: 0\n",
      "Number of tokens: 273373\n",
      "Field names: []\n",
      "Positions:   true\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading index\n",
    "index_ref = pt.IndexRef.of(\"./indexes/default/data.properties\")\n",
    "index = pt.IndexFactory.of(index_ref)\n",
    "print(index.getCollectionStatistics().toString())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9b57a6",
   "metadata": {},
   "source": [
    "# Sparse IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64efcd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Sparse IR Systems\n",
    "tf = pt.BatchRetrieve(index, wmodel=\"Tf\")\n",
    "tf_idf = pt.BatchRetrieve(index, wmodel=\"TF_IDF\")\n",
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e43b4c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>ndcg_cut_10</th>\n",
       "      <th>P_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TF</td>\n",
       "      <td>0.610184</td>\n",
       "      <td>0.789583</td>\n",
       "      <td>0.851008</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.622287</td>\n",
       "      <td>0.798228</td>\n",
       "      <td>0.840808</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.628454</td>\n",
       "      <td>0.800955</td>\n",
       "      <td>0.842503</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name       map      ndcg  ndcg_cut_10      P_10\n",
       "0      TF  0.610184  0.789583     0.851008  0.800000\n",
       "1  TF-IDF  0.622287  0.798228     0.840808  0.766667\n",
       "2    BM25  0.628454  0.800955     0.842503  0.766667"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate models on queries using PyTerrier Experiment Interface\n",
    "qrels = qrels.astype({'label': 'int32'})\n",
    "pt.Experiment(\n",
    "    retr_systems = [tf, tf_idf, bm25],\n",
    "    names =  [\"TF\", \"TF-IDF\", \"BM25\"],\n",
    "    topics = queries, \n",
    "    qrels = qrels,\n",
    "    eval_metrics = [\"map\", \"ndcg\", \"ndcg_cut_10\", \"P_10\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a723aa",
   "metadata": {},
   "source": [
    "# Dense IR - Using Re-Ranking with Transformers - Hybrid BM25 Cross-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d5b3df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder \n",
    "model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77ae5707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1015979</td>\n",
       "      <td>205</td>\n",
       "      <td>1015979</td>\n",
       "      <td>0</td>\n",
       "      <td>20.927815</td>\n",
       "      <td>president of chile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1015979</td>\n",
       "      <td>2435</td>\n",
       "      <td>229754</td>\n",
       "      <td>1</td>\n",
       "      <td>18.834027</td>\n",
       "      <td>president of chile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015979</td>\n",
       "      <td>2417</td>\n",
       "      <td>1186821</td>\n",
       "      <td>2</td>\n",
       "      <td>18.584731</td>\n",
       "      <td>president of chile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1015979</td>\n",
       "      <td>546</td>\n",
       "      <td>2226456</td>\n",
       "      <td>3</td>\n",
       "      <td>14.702179</td>\n",
       "      <td>president of chile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1015979</td>\n",
       "      <td>549</td>\n",
       "      <td>1514612</td>\n",
       "      <td>4</td>\n",
       "      <td>13.293413</td>\n",
       "      <td>president of chile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>8438</td>\n",
       "      <td>983</td>\n",
       "      <td>329834</td>\n",
       "      <td>15</td>\n",
       "      <td>9.048160</td>\n",
       "      <td>mexican cuisine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267</th>\n",
       "      <td>8438</td>\n",
       "      <td>448</td>\n",
       "      <td>198481</td>\n",
       "      <td>16</td>\n",
       "      <td>7.538971</td>\n",
       "      <td>mexican cuisine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268</th>\n",
       "      <td>8438</td>\n",
       "      <td>6</td>\n",
       "      <td>11904</td>\n",
       "      <td>17</td>\n",
       "      <td>7.484533</td>\n",
       "      <td>mexican cuisine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>8438</td>\n",
       "      <td>2053</td>\n",
       "      <td>409</td>\n",
       "      <td>18</td>\n",
       "      <td>7.351817</td>\n",
       "      <td>mexican cuisine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>8438</td>\n",
       "      <td>2374</td>\n",
       "      <td>1612995</td>\n",
       "      <td>19</td>\n",
       "      <td>6.998401</td>\n",
       "      <td>mexican cuisine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          qid  docid    docno  rank      score               query\n",
       "0     1015979    205  1015979     0  20.927815  president of chile\n",
       "1     1015979   2435   229754     1  18.834027  president of chile\n",
       "2     1015979   2417  1186821     2  18.584731  president of chile\n",
       "3     1015979    546  2226456     3  14.702179  president of chile\n",
       "4     1015979    549  1514612     4  13.293413  president of chile\n",
       "...       ...    ...      ...   ...        ...                 ...\n",
       "2266     8438    983   329834    15   9.048160     mexican cuisine\n",
       "2267     8438    448   198481    16   7.538971     mexican cuisine\n",
       "2268     8438      6    11904    17   7.484533     mexican cuisine\n",
       "2269     8438   2053      409    18   7.351817     mexican cuisine\n",
       "2270     8438   2374  1612995    19   6.998401     mexican cuisine\n",
       "\n",
       "[180 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Retrive top-K documents using BM25\n",
    "K = 20 \n",
    "top_k_bm25 = bm25 % K\n",
    "\n",
    "init = top_k_bm25.transform(queries)\n",
    "init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20e8728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-Ranking documents using a Cross-Encoder\n",
    "import os\n",
    "cross_run = []\n",
    "model_name = 'cross'\n",
    "for i in range(len(queries)):\n",
    "    qid, query = queries.iloc[i]\n",
    "\n",
    "    # Retrieve top-K document IDs for query i \n",
    "    qid_docnos = init[init['qid'] == qid]['docno']\n",
    "    \n",
    "    # Retrive docno and text for top-K documents\n",
    "    qid_docnos = docs[docs['docno'].isin(qid_docnos)]['docno']\n",
    "    qid_docs = docs[docs['docno'].isin(qid_docnos)]['text']\n",
    "    \n",
    "    \n",
    "    # Concatenate the query and documents and predict the scores for the pairs [query, passage]\n",
    "    model_inputs = [[query, doc] for doc in qid_docs]\n",
    "    docno_inputs = [docno for docno in qid_docnos]\n",
    "    scores = model.predict(model_inputs)\n",
    "\n",
    "    # Sort the scores in decreasing order\n",
    "    results = [{'input': inp, 'docno': docno, 'score': score} for inp, docno, score in zip(model_inputs, docno_inputs, scores)]\n",
    "    results = sorted(results, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "    # Save the results in TREC format\n",
    "    for rank, hit in enumerate(results):\n",
    "        docno = hit['docno']\n",
    "        score = hit['score']\n",
    "        row_str = f\"{qid} 0 {docno} {rank} {score} {model_name}\"\n",
    "        cross_run.append(row_str)    \n",
    "    \n",
    "# Store ranking on disk in TREC format\n",
    "if os.path.exists('./outputs') == False:\n",
    "    os.makedirs('./outputs')\n",
    "with open('./' + f\"outputs/{model_name}.run\", \"w\") as f:\n",
    "    for l in cross_run:\n",
    "        f.write(l + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b12025",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5bd6b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytrec_eval\n",
    "\n",
    "# Load qrels in a dictionary\n",
    "qrels_dict = dict()\n",
    "for _, r in qrels.iterrows():\n",
    "    qid, docno, label, iteration = r\n",
    "    if qid not in qrels_dict:\n",
    "        qrels_dict[qid] = dict()\n",
    "    qrels_dict[qid][docno] = int(label)\n",
    "\n",
    "# Build evaluator based on the qrels and metrics\n",
    "metrics = {\"ndcg_cut_5\", \"ndcg_cut_10\", \"P_5\", \"P_10\"}\n",
    "my_qrel = {q: d for q, d in qrels_dict.items()}\n",
    "evaluator = pytrec_eval.RelevanceEvaluator(my_qrel, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f146dfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Cross-Encoder run\n",
    "with open(\"outputs/cross.run\", 'r') as f_run:\n",
    "    cross_run = pytrec_eval.parse_run(f_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc5a1e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_5 \t 0.9296490683037353\n",
      "P_5 \t 0.9555555555555555\n",
      "P_10 \t 0.8111111111111111\n",
      "ndcg_cut_10 \t 0.8840626039066009\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Cross-Encoder model\n",
    "cross_evals = evaluator.evaluate(cross_run)\n",
    "\n",
    "# Compute performance in different metrics for each query\n",
    "cross_metric2vals = {m: [] for m in metrics}\n",
    "for q, d in cross_evals.items():\n",
    "    for m, val in d.items():\n",
    "        cross_metric2vals[m].append(val)\n",
    "\n",
    "# Average results by query\n",
    "cross_metric2avg = dict()\n",
    "for m in metrics:\n",
    "    val = pytrec_eval.compute_aggregated_measure(m, cross_metric2vals[m])\n",
    "    cross_metric2avg[m] = val\n",
    "    print(m, '\\t', val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "447c96ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b4/_v02ff4x0255n8r1cwfppc4r0000gn/T/ipykernel_61333/3355555803.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  experiment.append(cross_metric2avg, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ndcg_cut_5</th>\n",
       "      <th>P_5</th>\n",
       "      <th>P_10</th>\n",
       "      <th>ndcg_cut_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TF</td>\n",
       "      <td>0.861466</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.851008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.877270</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.840808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.878503</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.842503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BM25 &gt;&gt; Cross-Encoder</td>\n",
       "      <td>0.929649</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>0.884063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name  ndcg_cut_5       P_5      P_10  ndcg_cut_10\n",
       "0                     TF    0.861466  0.866667  0.800000     0.851008\n",
       "1                 TF-IDF    0.877270  0.888889  0.766667     0.840808\n",
       "2                   BM25    0.878503  0.888889  0.766667     0.842503\n",
       "3  BM25 >> Cross-Encoder    0.929649  0.955556  0.811111     0.884063"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare system performance\n",
    "experiment = pt.Experiment(\n",
    "    retr_systems=[tf, tf_idf, bm25],\n",
    "    names=['TF', 'TF-IDF', 'BM25'],\n",
    "    topics=queries,\n",
    "    qrels=qrels,\n",
    "    eval_metrics=metrics)\n",
    "\n",
    "cross_metric2avg['name'] = 'BM25 >> Cross-Encoder'\n",
    "experiment.append(cross_metric2avg, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1642f52",
   "metadata": {},
   "source": [
    "# Dense IR - Using Dense Passage Retrieval (DPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03cb889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEE dpr_example.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "567ae02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load the SBERT model and retrieve using cosine-similarity\n",
    "#model = DRES(models.SentenceBERT(\"msmarco-distilbert-base-tas-b\"), batch_size=16)\n",
    "#retriever = EvaluateRetrieval(model, score_function=\"dot\") # or \"cos_sim\" for cosine similarity\n",
    "#results = retriever.retrieve(corpus, queries)\n",
    "#results = retriever.retrieve(new_docs, new_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d3959a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Evaluate your model with NDCG@k, MAP@K, Recall@K and Precision@K  where k = [1,3,5,10,100,1000] \n",
    "#ndcg, _map, recall, precision = retriever.evaluate(new_qrels, results, retriever.k_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
